{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODVwyVUjgarnPS99h2P/9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee3072/cs390nip-lab4/blob/main/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG2CtobHA47z"
      },
      "source": [
        "# CS390-NIP GAN lab\n",
        "# Max Jacobson / Sri Cherukuri / Anthony Niemiec\n",
        "# FA2020\n",
        "# uses Fashion MNIST https://www.kaggle.com/zalando-research/fashionmnist \n",
        "# uses CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.misc import imsave\n",
        "import random\n",
        "\n",
        "random.seed(1618)\n",
        "np.random.seed(1618)\n",
        "tf.compat.v1.set_random_seed(1618)\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# NOTE: mnist_d is no credit\n",
        "# NOTE: cifar_10 is extra credit\n",
        "#DATASET = \"mnist_d\"\n",
        "DATASET = \"mnist_f\"\n",
        "#DATASET = \"cifar_10\"\n",
        "\n",
        "if DATASET == \"mnist_d\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    LABEL = \"numbers\"\n",
        "\n",
        "elif DATASET == \"mnist_f\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (28, 28, 1)\n",
        "    CLASSLIST = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "    # TODO: choose a label to train on from the CLASSLIST above\n",
        "    LABEL = \"coat\"\n",
        "\n",
        "elif DATASET == \"cifar_10\":\n",
        "    IMAGE_SHAPE = (IH, IW, IZ) = (32, 32, 3)\n",
        "    CLASSLIST = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "    LABEL = \"airplane\"\n",
        "\n",
        "IMAGE_SIZE = IH*IW*IZ\n",
        "\n",
        "NOISE_SIZE = 100    # length of noise array\n",
        "\n",
        "# file prefixes and directory\n",
        "OUTPUT_NAME = DATASET + \"_\" + LABEL\n",
        "OUTPUT_DIR = \"./outputs/\" + OUTPUT_NAME\n",
        "\n",
        "# NOTE: switch to True in order to receive debug information\n",
        "VERBOSE_OUTPUT = False\n",
        "\n",
        "################################### DATA FUNCTIONS ###################################\n",
        "\n",
        "# Load in and report the shape of dataset\n",
        "def getRawData():\n",
        "    if DATASET == \"mnist_f\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif DATASET == \"cifar_10\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.cifar10.load_data()\n",
        "    elif DATASET == \"mnist_d\":\n",
        "        (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.mnist.load_data()\n",
        "    print(\"Shape of xTrain dataset: %s.\" % str(xTrain.shape))\n",
        "    print(\"Shape of yTrain dataset: %s.\" % str(yTrain.shape))\n",
        "    print(\"Shape of xTest dataset: %s.\" % str(xTest.shape))\n",
        "    print(\"Shape of yTest dataset: %s.\" % str(yTest.shape))\n",
        "    return ((xTrain, yTrain), (xTest, yTest))\n",
        "\n",
        "# Filter out the dataset to only include images with our LABEL, meaning we may also discard\n",
        "# class labels for the images because we know exactly what to expect\n",
        "def preprocessData(raw):\n",
        "    ((xTrain, yTrain), (xTest, yTest)) = raw\n",
        "    if DATASET == \"mnist_d\":\n",
        "        xP = np.r_[xTrain, xTest]\n",
        "    else:\n",
        "        c = CLASSLIST.index(LABEL)\n",
        "        x = np.r_[xTrain, xTest]\n",
        "        y = np.r_[yTrain, yTest].flatten()\n",
        "        ilist = [i for i in range(y.shape[0]) if y[i] == c]\n",
        "        xP = x[ilist]\n",
        "    # NOTE: Normalize from 0 to 1 or -1 to 1\n",
        "    #xP = xP/255.0\n",
        "    xP = xP/127.5 - 1\n",
        "    print(\"Shape of Preprocessed dataset: %s.\" % str(xP.shape))\n",
        "    return xP\n",
        "\n",
        "\n",
        "################################### CREATING A GAN ###################################\n",
        "\n",
        "# Model that discriminates between fake and real dataset images\n",
        "def buildDiscriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # TODO: build a discriminator which takes in a (28 x 28 x 1) image - possibly from mnist_f\n",
        "    #       and possibly from the generator - and outputs a single digit REAL (1) or FAKE (0)\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = IMAGE_SHAPE)\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "# Model that generates a fake image from random noise\n",
        "def buildGenerator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # TODO: build a generator which takes in a (NOISE_SIZE) noise array and outputs a fake\n",
        "    #       mnist_f (28 x 28 x 1) image\n",
        "\n",
        "    # Creating a Keras Model out of the network\n",
        "    inputTensor = Input(shape = (NOISE_SIZE,))\n",
        "    return Model(inputTensor, model(inputTensor))\n",
        "\n",
        "def buildGAN(images, epochs = 40000, batchSize = 32, loggingInterval = 0):\n",
        "    # Setup\n",
        "    opt = Adam(lr = 0.0002)\n",
        "    loss = \"binary_crossentropy\"\n",
        "\n",
        "    # Setup adversary\n",
        "    adversary = buildDiscriminator()\n",
        "    adversary.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])\n",
        "\n",
        "    # Setup generator and GAN\n",
        "    adversary.trainable = False                     # freeze adversary's weights when training GAN\n",
        "    generator = buildGenerator()                    # generator is trained within GAN in relation to adversary performance\n",
        "    noise = Input(shape = (NOISE_SIZE,))\n",
        "    gan = Model(noise, adversary(generator(noise))) # GAN feeds generator into adversary\n",
        "    gan.compile(loss = loss, optimizer = opt)\n",
        "\n",
        "    # Training\n",
        "    trueCol = np.ones((batchSize, 1))\n",
        "    falseCol = np.zeros((batchSize, 1))\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Train discriminator with a true and false batch\n",
        "        batch = images[np.random.randint(0, images.shape[0], batchSize)]\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genImages = generator.predict(noise)\n",
        "        advTrueLoss = adversary.train_on_batch(batch, trueCol)\n",
        "        advFalseLoss = adversary.train_on_batch(genImages, falseCol)\n",
        "        advLoss = np.add(advTrueLoss, advFalseLoss) * 0.5\n",
        "\n",
        "        # Train generator by training GAN while keeping adversary component constant\n",
        "        noise = np.random.normal(0, 1, (batchSize, NOISE_SIZE))\n",
        "        genLoss = gan.train_on_batch(noise, trueCol)\n",
        "\n",
        "        # Logging\n",
        "        if loggingInterval > 0 and epoch % loggingInterval == 0:\n",
        "            print(\"\\tEpoch %d:\" % epoch)\n",
        "            print(\"\\t\\tDiscriminator loss: %f.\" % advLoss[0])\n",
        "            print(\"\\t\\tDiscriminator accuracy: %.2f%%.\" % (100 * advLoss[1]))\n",
        "            print(\"\\t\\tGenerator loss: %f.\" % genLoss)\n",
        "            runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_test_%d.png\" % (epoch / loggingInterval))\n",
        "\n",
        "    return (generator, adversary, gan)\n",
        "\n",
        "# Generates an image using given generator\n",
        "def runGAN(generator, outfile):\n",
        "    noise = np.random.normal(0, 1, (1, NOISE_SIZE)) # generate a random noise array\n",
        "    img = generator.predict(noise)[0]               # run generator on noise\n",
        "    img = np.squeeze(img)                           # readjust image shape if needed\n",
        "    img = (0.5*img + 0.5)*255                       # adjust values to range from 0 to 255 as needed\n",
        "    imsave(outfile, img)                            # store resulting image\n",
        "\n",
        "\n",
        "################################### RUNNING THE PIPELINE #############################\n",
        "\n",
        "def main():\n",
        "    print(\"Starting %s image generator program.\" % LABEL)\n",
        "    # Make output directory\n",
        "    if not os.path.exists(OUTPUT_DIR):\n",
        "        os.makedirs(OUTPUT_DIR)\n",
        "    # Receive all of mnist_f\n",
        "    raw = getRawData()\n",
        "    # Filter for just the class we are trying to generate\n",
        "    data = preprocessData(raw)\n",
        "    # Create and train all facets of the GAN\n",
        "    (generator, adv, gan) = buildGAN(data, epochs = 60000, loggingInterval = 1000)\n",
        "    # Utilize our spooky neural net gimmicks to create realistic counterfeit images\n",
        "    for i in range(10):\n",
        "        runGAN(generator, OUTPUT_DIR + \"/\" + OUTPUT_NAME + \"_final_%d.png\" % i)\n",
        "    print(\"Images saved in %s directory.\" % OUTPUT_DIR)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ_Vek5_DF0e"
      },
      "source": [
        "!pip install -U scipy==1.2.0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}